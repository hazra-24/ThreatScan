{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea18275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreatScan Project: Spam, Phishing, and Scam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe03ce4-6b87-47c2-8877-9d56afaa120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# First, install all the necessary libraries for the project\n",
    "# Run this cell once to make sure your environment is set up\n",
    "!pip install pandas numpy scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1362326b-c707-4603-bc54-641b594f8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Message Spam Detection\n",
    "##This section loads the `spam.csv` dataset, trains a Na√Øve Bayes classifier to identify spam messages, and provides a function to test new messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee64323-963a-485f-800b-a8cfe489a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries for message spam detection imported.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for message spam detection\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Libraries for message spam detection imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6118dffa-a0cc-4e49-aa08-3e92626de180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam dataset loaded and cleaned successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "1    0.0  Go until jurong point, crazy.. Available only ...\n",
       "2    0.0                      Ok lar... Joking wif u oni...\n",
       "3    1.0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "4    0.0  U dun say so early hor... U c already then say...\n",
       "5    0.0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset and preprocess the text data\n",
    "try:\n",
    "    # 1. Load the CSV without a header\n",
    "    df_msg = pd.read_csv('spam.csv', encoding='latin-1', header=None)\n",
    "\n",
    "    # 2. Select the first two columns\n",
    "    df_msg = df_msg.iloc[:, :2]\n",
    "    \n",
    "    # 3. Rename the columns\n",
    "    df_msg.columns = ['label', 'message']\n",
    "\n",
    "    # 4. Map the values in the 'label' column\n",
    "    df_msg['label'] = df_msg['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "    # 5. Drop any rows where the label is now NaN (THIS IS THE FIX)\n",
    "    df_msg.dropna(inplace=True)\n",
    "\n",
    "    print(\"Spam dataset loaded and cleaned successfully.\")\n",
    "    display(df_msg.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'spam.csv' not found. Make sure it's in the same folder as this notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b77157a5-5750-4dcd-b35a-ae80447af5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Spam Model Accuracy: 98.39%\n"
     ]
    }
   ],
   "source": [
    "# Split data, vectorize text, and train the model\n",
    "if 'df_msg' in locals():\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_msg['message'], df_msg['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Vectorize the text data using CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Initialize and train the Naive Bayes model\n",
    "    spam_model = MultinomialNB()\n",
    "    spam_model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Make predictions and check the model's accuracy\n",
    "    predictions = spam_model.predict(X_test_vec)\n",
    "    print(f\"Message Spam Model Accuracy: {accuracy_score(y_test, predictions):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4751884d-2891-4753-bcfc-13eea81e2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message 'Congratulations! You've won a $1000 Walmart gift card. Click here to claim.' is: Model not trained yet.\n",
      "The message 'Hey, are we still on for the meeting tomorrow at 2 PM?' is: Model not trained yet.\n"
     ]
    }
   ],
   "source": [
    "# Create a function to predict any new message\n",
    "def predict_message(message):\n",
    "    \"\"\"Takes a message string and predicts if it's Spam or Not Spam.\"\"\"\n",
    "    if 'spam_model' in locals():\n",
    "        message_vec = vectorizer.transform([message])\n",
    "        prediction = spam_model.predict(message_vec)\n",
    "        return \"Spam\" if prediction[0] == 1 else \"Not Spam\"\n",
    "    else:\n",
    "        return \"Model not trained yet.\"\n",
    "\n",
    "# --- Test the message prediction function ---\n",
    "test_message_1 = \"Congratulations! You've won a $1000 Walmart gift card. Click here to claim.\"\n",
    "print(f\"The message '{test_message_1}' is: {predict_message(test_message_1)}\")\n",
    "\n",
    "test_message_2 = \"Hey, are we still on for the meeting tomorrow at 2 PM?\"\n",
    "print(f\"The message '{test_message_2}' is: {predict_message(test_message_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448391f3-0b1a-4778-925b-0e892f14c5ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2094872278.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mThis section is for the logic from your `url_safety_checker.py` file. You will need to load the `malicious_phish.csv` dataset and copy your feature extraction and model training code here.\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Part 2: Phishing URL Detection\n",
    "\n",
    "This section is for the logic from your `url_safety_checker.py` file. You will need to load the `malicious_phish.csv` dataset and copy your feature extraction and model training code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b13b35a-7c56-4dcc-b9f2-f4395e699ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder: Add your URL detection code here.\n"
     ]
    }
   ],
   "source": [
    "# --- PASTE YOUR URL DETECTION CODE FROM YOUR .py FILE HERE ---\n",
    "# Example:\n",
    "# 1. Load the 'malicious_phish.csv' dataset using pandas.\n",
    "# 2. Define and apply your feature extraction functions.\n",
    "# 3. Train your model.\n",
    "# 4. Create your prediction function.\n",
    "\n",
    "print(\"Placeholder: Add your URL detection code here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30eb4e-72fd-45c2-8919-5d9ca3424da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
